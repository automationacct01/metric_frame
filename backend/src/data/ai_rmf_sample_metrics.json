{
  "framework_code": "ai_rmf",
  "metrics": [
    {
      "metric_number": "AI-GOV-001",
      "name": "AI Systems Inventory Completeness",
      "description": "Percentage of AI systems documented in organizational inventory",
      "formula": "AI systems in inventory / Total known AI systems",
      "risk_definition": "Incomplete AI inventory creates blind spots in risk management, prevents proper oversight of AI deployments, and may lead to unmonitored systems causing harm or compliance violations.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.6",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 75,
      "priority_rank": 1,
      "owner_function": "AI Governance",
      "data_source": "AI Registry",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-002",
      "name": "AI Policy Coverage",
      "description": "Percentage of AI risk categories covered by organizational policies",
      "formula": "AI risk categories with policies / Total AI risk categories",
      "risk_definition": "Gaps in AI policy coverage leave the organization exposed to unaddressed risks including ethical violations, regulatory non-compliance, and inconsistent AI governance practices.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 68,
      "priority_rank": 1,
      "owner_function": "AI Governance",
      "data_source": "Policy Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-003",
      "name": "AI Risk Management Training Completion",
      "description": "Percentage of relevant personnel trained on AI risk management",
      "formula": "Personnel with completed AI risk training / Total personnel requiring training",
      "risk_definition": "Untrained personnel may unknowingly introduce AI risks, fail to identify issues during development or operation, and make decisions that compromise AI trustworthiness.",
      "function_code": "govern",
      "category_code": "GOVERN-2",
      "subcategory_code": "GOVERN-2.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 52,
      "priority_rank": 2,
      "owner_function": "HR/Training",
      "data_source": "LMS",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-004",
      "name": "AI Team Diversity Index",
      "description": "Diversity score of AI development and governance teams",
      "formula": "Composite score based on demographic, disciplinary, and experiential diversity metrics",
      "risk_definition": "Lack of diversity in AI teams leads to blind spots in bias detection, limited perspectives on societal impacts, and AI systems that may not serve all user populations equitably.",
      "function_code": "govern",
      "category_code": "GOVERN-3",
      "subcategory_code": "GOVERN-3.1",
      "direction": "higher_is_better",
      "target_value": 80,
      "target_units": "score",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "HR/AI Teams",
      "data_source": "HR Systems",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-GOV-005",
      "name": "AI Regulatory Compliance Rate",
      "description": "Percentage of AI systems compliant with applicable legal and regulatory requirements",
      "formula": "Compliant AI systems / Total AI systems subject to regulations",
      "risk_definition": "Non-compliance with AI regulations exposes the organization to fines, legal action, reputational damage, and potential operational restrictions on AI use.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 82,
      "priority_rank": 1,
      "owner_function": "Legal/Compliance",
      "data_source": "Compliance Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-006",
      "name": "AI Legal Risk Documentation Rate",
      "description": "Percentage of AI systems with documented legal risk assessments",
      "formula": "AI systems with legal risk documentation / Total AI systems",
      "risk_definition": "Undocumented legal risks create liability exposure, complicate incident response, and may result in unexpected regulatory penalties or litigation.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 65,
      "priority_rank": 1,
      "owner_function": "Legal/Compliance",
      "data_source": "Legal Risk Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-007",
      "name": "AI Risk Tolerance Documentation",
      "description": "Percentage of AI use cases with documented risk tolerance levels",
      "formula": "AI use cases with defined risk tolerance / Total AI use cases",
      "risk_definition": "Without documented risk tolerance, teams cannot make consistent decisions about acceptable AI risks, leading to inconsistent risk management and potential over/under-investment in controls.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 58,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-008",
      "name": "AI Risk Management Process Transparency Score",
      "description": "Assessment score measuring transparency of AI risk management processes and decisions",
      "formula": "Weighted score of transparency criteria (documentation, communication, accessibility)",
      "risk_definition": "Opaque risk management processes undermine stakeholder trust, hinder oversight, and may mask systemic issues in AI governance.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.4",
      "direction": "higher_is_better",
      "target_value": 85,
      "target_units": "score",
      "current_value": 68,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Governance Assessment",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-009",
      "name": "AI Risk Review Frequency",
      "description": "Number of formal AI risk reviews conducted per year",
      "formula": "Count of completed AI risk reviews in period",
      "risk_definition": "Infrequent risk reviews allow AI risks to accumulate undetected, reduce organizational awareness of emerging threats, and delay necessary risk mitigation actions.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.5",
      "direction": "higher_is_better",
      "target_value": 4,
      "target_units": "per year",
      "current_value": 2,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Review Calendar",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-010",
      "name": "AI Decommissioning Compliance Rate",
      "description": "Percentage of retired AI systems properly decommissioned per established procedures",
      "formula": "Properly decommissioned AI systems / Total retired AI systems",
      "risk_definition": "Improper decommissioning leaves orphaned AI systems that may continue operating without oversight, retain sensitive data inappropriately, or create security vulnerabilities.",
      "function_code": "govern",
      "category_code": "GOVERN-1",
      "subcategory_code": "GOVERN-1.7",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 78,
      "priority_rank": 2,
      "owner_function": "AI Operations",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-GOV-011",
      "name": "AI RACI Matrix Completeness",
      "description": "Percentage of AI risk management activities with documented RACI assignments",
      "formula": "Activities with complete RACI / Total AI risk management activities",
      "risk_definition": "Unclear roles and responsibilities lead to gaps in AI risk coverage, duplicated efforts, and accountability failures when incidents occur.",
      "function_code": "govern",
      "category_code": "GOVERN-2",
      "subcategory_code": "GOVERN-2.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Governance Documentation",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-012",
      "name": "Executive AI Oversight Engagement",
      "description": "Number of executive-level AI oversight meetings per quarter",
      "formula": "Count of executive AI governance meetings",
      "risk_definition": "Insufficient executive engagement reduces strategic alignment of AI initiatives, limits resource allocation for risk management, and weakens accountability for AI outcomes.",
      "function_code": "govern",
      "category_code": "GOVERN-2",
      "subcategory_code": "GOVERN-2.3",
      "direction": "higher_is_better",
      "target_value": 4,
      "target_units": "per quarter",
      "current_value": 2,
      "priority_rank": 1,
      "owner_function": "Executive Leadership",
      "data_source": "Executive Calendar",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-013",
      "name": "Human-AI Oversight Policy Coverage",
      "description": "Percentage of AI systems with defined human oversight policies",
      "formula": "AI systems with human oversight policies / Total AI systems",
      "risk_definition": "AI systems without human oversight policies may operate autonomously in inappropriate contexts, reducing accountability and increasing risk of undetected errors or harms.",
      "function_code": "govern",
      "category_code": "GOVERN-3",
      "subcategory_code": "GOVERN-3.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 55,
      "priority_rank": 1,
      "owner_function": "AI Governance",
      "data_source": "Policy Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-014",
      "name": "AI Override Mechanism Availability",
      "description": "Percentage of production AI systems with functional human override capabilities",
      "formula": "AI systems with tested override mechanisms / Total production AI systems",
      "risk_definition": "AI systems without override capabilities cannot be quickly controlled when issues arise, potentially allowing harmful outputs or decisions to continue unchecked.",
      "function_code": "govern",
      "category_code": "GOVERN-3",
      "subcategory_code": "GOVERN-3.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 68,
      "priority_rank": 1,
      "owner_function": "AI Operations",
      "data_source": "System Configuration Database",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-GOV-015",
      "name": "AI Safety Culture Assessment Score",
      "description": "Survey-based assessment of organizational AI safety culture maturity",
      "formula": "Weighted average of safety culture survey dimensions",
      "risk_definition": "Weak safety culture leads to normalization of risky AI practices, suppression of concerns, and organizational blind spots to emerging AI harms.",
      "function_code": "govern",
      "category_code": "GOVERN-4",
      "subcategory_code": "GOVERN-4.1",
      "direction": "higher_is_better",
      "target_value": 80,
      "target_units": "score",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Employee Survey System",
      "collection_frequency": "annually",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-GOV-016",
      "name": "AI Impact Documentation Rate",
      "description": "Percentage of AI systems with documented potential impacts and risks",
      "formula": "AI systems with impact documentation / Total AI systems",
      "risk_definition": "Undocumented impacts prevent informed decision-making, hinder stakeholder communication, and may result in unexpected negative consequences.",
      "function_code": "govern",
      "category_code": "GOVERN-4",
      "subcategory_code": "GOVERN-4.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 58,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-017",
      "name": "AI Incident Information Sharing Rate",
      "description": "Percentage of AI incidents shared internally for organizational learning",
      "formula": "AI incidents shared across teams / Total AI incidents",
      "risk_definition": "Failure to share incident information prevents organizational learning, allows similar issues to recur, and misses opportunities to improve AI systems across the organization.",
      "function_code": "govern",
      "category_code": "GOVERN-4",
      "subcategory_code": "GOVERN-4.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 2,
      "owner_function": "AI Operations",
      "data_source": "Incident Management System",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-GOV-018",
      "name": "External Stakeholder Feedback Collection Rate",
      "description": "Percentage of AI systems with active external stakeholder feedback mechanisms",
      "formula": "AI systems with external feedback channels / Total customer-facing AI systems",
      "risk_definition": "Without external feedback mechanisms, organizations miss critical signals about AI harms, fail to understand real-world impacts, and cannot address stakeholder concerns promptly.",
      "function_code": "govern",
      "category_code": "GOVERN-5",
      "subcategory_code": "GOVERN-5.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 45,
      "priority_rank": 2,
      "owner_function": "Product Management",
      "data_source": "Product Systems",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-GOV-019",
      "name": "AI Feedback Integration Rate",
      "description": "Percentage of validated stakeholder feedback incorporated into AI improvements",
      "formula": "Feedback items addressed / Total validated feedback items",
      "risk_definition": "Ignoring stakeholder feedback perpetuates known issues, erodes trust, and misses opportunities to improve AI fairness and effectiveness.",
      "function_code": "govern",
      "category_code": "GOVERN-5",
      "subcategory_code": "GOVERN-5.2",
      "direction": "higher_is_better",
      "target_value": 80,
      "target_units": "percent",
      "current_value": 52,
      "priority_rank": 2,
      "owner_function": "Product Management",
      "data_source": "Feedback Tracking System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-GOV-020",
      "name": "Third-Party AI Policy Coverage",
      "description": "Percentage of third-party AI relationships governed by formal policies",
      "formula": "Third-party AI relationships with policies / Total third-party AI relationships",
      "risk_definition": "Ungoverned third-party AI relationships create supply chain risks, unclear liability, and potential regulatory exposure from vendor AI practices.",
      "function_code": "govern",
      "category_code": "GOVERN-6",
      "subcategory_code": "GOVERN-6.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 62,
      "priority_rank": 1,
      "owner_function": "Vendor Management",
      "data_source": "Vendor Risk Platform",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-021",
      "name": "AI IP Risk Assessment Completion",
      "description": "Percentage of AI systems assessed for intellectual property risks",
      "formula": "AI systems with IP risk assessment / Total AI systems",
      "risk_definition": "Unassessed IP risks may result in infringement claims, licensing violations, and unexpected legal liability from AI training data or outputs.",
      "function_code": "govern",
      "category_code": "GOVERN-6",
      "subcategory_code": "GOVERN-6.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 48,
      "priority_rank": 2,
      "owner_function": "Legal/Compliance",
      "data_source": "Legal Risk Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-GOV-022",
      "name": "AI Supply Chain Contingency Plan Coverage",
      "description": "Percentage of critical third-party AI dependencies with documented contingency plans",
      "formula": "Third-party AI with contingency plans / Critical third-party AI dependencies",
      "risk_definition": "Without contingency plans, third-party AI disruptions can halt critical business processes, with no clear path to maintain operations or transition to alternatives.",
      "function_code": "govern",
      "category_code": "GOVERN-6",
      "subcategory_code": "GOVERN-6.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 42,
      "priority_rank": 1,
      "owner_function": "Business Continuity",
      "data_source": "BCP Documentation",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MAP-001",
      "name": "AI System Purpose Documentation",
      "description": "Percentage of AI systems with documented intended purpose and context",
      "formula": "AI systems with documented purpose / Total AI systems",
      "risk_definition": "Undocumented AI purposes lead to scope creep, misuse of systems beyond their validated contexts, and inability to assess whether systems are being used appropriately.",
      "function_code": "map",
      "category_code": "MAP-1",
      "subcategory_code": "MAP-1.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 80,
      "priority_rank": 1,
      "owner_function": "AI Governance",
      "data_source": "AI Registry",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAP-002",
      "name": "AI Risk Assessment Completion",
      "description": "Percentage of AI systems with completed risk assessments",
      "formula": "AI systems with completed risk assessments / Total AI systems",
      "risk_definition": "AI systems without risk assessments may harbor unknown vulnerabilities, create unexpected harms, and expose the organization to regulatory penalties and reputational damage.",
      "function_code": "map",
      "category_code": "MAP-4",
      "subcategory_code": "MAP-4.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 65,
      "priority_rank": 1,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Assessment System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAP-003",
      "name": "AI Impact Assessment Coverage",
      "description": "Percentage of high-risk AI systems with impact assessments",
      "formula": "High-risk AI systems with impact assessments / Total high-risk AI systems",
      "risk_definition": "High-risk AI without impact assessments may cause significant harm to individuals or groups, result in regulatory violations, and damage organizational trust and reputation.",
      "function_code": "map",
      "category_code": "MAP-5",
      "subcategory_code": "MAP-5.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 45,
      "priority_rank": 1,
      "owner_function": "AI Ethics",
      "data_source": "Impact Assessment Records",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-MAP-004",
      "name": "AI Team Interdisciplinary Representation",
      "description": "Percentage of AI projects with diverse disciplinary expertise on the team",
      "formula": "AI projects with interdisciplinary teams / Total AI projects",
      "risk_definition": "Homogeneous AI teams miss critical perspectives, fail to identify risks outside their expertise, and may create systems that don't serve diverse user needs.",
      "function_code": "map",
      "category_code": "MAP-1",
      "subcategory_code": "MAP-1.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 58,
      "priority_rank": 2,
      "owner_function": "Project Management",
      "data_source": "Project Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MAP-005",
      "name": "AI Mission Alignment Documentation",
      "description": "Percentage of AI systems with documented alignment to organizational mission",
      "formula": "AI systems with mission alignment documentation / Total AI systems",
      "risk_definition": "AI systems without clear mission alignment may drift from organizational values, create reputational risks, and fail to deliver intended strategic benefits.",
      "function_code": "map",
      "category_code": "MAP-1",
      "subcategory_code": "MAP-1.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAP-006",
      "name": "AI Business Value Documentation Rate",
      "description": "Percentage of AI systems with documented business value and use cases",
      "formula": "AI systems with business value documentation / Total AI systems",
      "risk_definition": "Undocumented business value makes it difficult to justify AI investments, prioritize resources, and evaluate whether systems are meeting their intended purposes.",
      "function_code": "map",
      "category_code": "MAP-1",
      "subcategory_code": "MAP-1.4",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 2,
      "owner_function": "Product Management",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAP-007",
      "name": "AI Risk Tolerance Documentation Rate",
      "description": "Percentage of AI systems with documented organizational risk tolerances",
      "formula": "AI systems with risk tolerance documentation / Total AI systems",
      "risk_definition": "Undocumented risk tolerance leads to inconsistent risk decisions, potential acceptance of unacceptable risks, and misalignment between AI practices and organizational values.",
      "function_code": "map",
      "category_code": "MAP-1",
      "subcategory_code": "MAP-1.5",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 48,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAP-008",
      "name": "AI Fairness Requirements Documentation",
      "description": "Percentage of AI systems with documented fairness requirements and constraints",
      "formula": "AI systems with fairness requirements / Total AI systems",
      "risk_definition": "AI systems without fairness requirements may perpetuate or amplify biases, discriminate against protected groups, and create legal and reputational exposure.",
      "function_code": "map",
      "category_code": "MAP-1",
      "subcategory_code": "MAP-1.6",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 42,
      "priority_rank": 1,
      "owner_function": "AI Ethics",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MAP-009",
      "name": "AI Task Definition Completeness",
      "description": "Percentage of AI systems with fully defined tasks and implementation methods",
      "formula": "AI systems with complete task definitions / Total AI systems",
      "risk_definition": "Incompletely defined AI tasks lead to scope creep, misaligned development, and systems that fail to meet user needs or operate outside intended parameters.",
      "function_code": "map",
      "category_code": "MAP-2",
      "subcategory_code": "MAP-2.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 75,
      "priority_rank": 2,
      "owner_function": "ML Engineering",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MAP-010",
      "name": "AI Knowledge Limits Documentation",
      "description": "Percentage of AI systems with documented knowledge limits and uncertainty bounds",
      "formula": "AI systems with knowledge limits documentation / Total AI systems",
      "risk_definition": "Undocumented knowledge limits lead to overreliance on AI, inappropriate use in edge cases, and decisions based on AI outputs outside their valid operating range.",
      "function_code": "map",
      "category_code": "MAP-2",
      "subcategory_code": "MAP-2.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 38,
      "priority_rank": 1,
      "owner_function": "ML Engineering",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "explainable_interpretable"
    },
    {
      "metric_number": "AI-MAP-011",
      "name": "AI Scientific Integrity Documentation",
      "description": "Percentage of AI systems with documented scientific integrity and TEVV considerations",
      "formula": "AI systems with scientific integrity documentation / Total AI systems",
      "risk_definition": "Lack of scientific rigor in AI development leads to unreliable systems, inability to reproduce results, and potential deployment of flawed or biased models.",
      "function_code": "map",
      "category_code": "MAP-2",
      "subcategory_code": "MAP-2.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 52,
      "priority_rank": 2,
      "owner_function": "ML Engineering",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MAP-012",
      "name": "AI Benefit Documentation Rate",
      "description": "Percentage of AI systems with documented potential benefits and performance expectations",
      "formula": "AI systems with benefit documentation / Total AI systems",
      "risk_definition": "Undocumented benefits make it difficult to measure AI success, justify continued investment, and identify when systems are underperforming.",
      "function_code": "map",
      "category_code": "MAP-3",
      "subcategory_code": "MAP-3.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 68,
      "priority_rank": 2,
      "owner_function": "Product Management",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAP-013",
      "name": "AI Cost and Impact Documentation",
      "description": "Percentage of AI systems with documented potential costs and non-monetary impacts",
      "formula": "AI systems with cost/impact documentation / Total AI systems",
      "risk_definition": "Undocumented costs and impacts lead to unexpected resource requirements, hidden harms to stakeholders, and inability to make informed deployment decisions.",
      "function_code": "map",
      "category_code": "MAP-3",
      "subcategory_code": "MAP-3.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 45,
      "priority_rank": 1,
      "owner_function": "AI Risk Management",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-MAP-014",
      "name": "AI Scope Specification Completeness",
      "description": "Percentage of AI systems with documented application scope and capability boundaries",
      "formula": "AI systems with scope specification / Total AI systems",
      "risk_definition": "Undefined scope leads to AI use outside validated boundaries, unpredictable behavior in edge cases, and potential deployment in inappropriate contexts.",
      "function_code": "map",
      "category_code": "MAP-3",
      "subcategory_code": "MAP-3.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "ML Engineering",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MAP-015",
      "name": "AI Societal Impact Assessment Coverage",
      "description": "Percentage of AI systems assessed for broader societal risks and benefits",
      "formula": "AI systems with societal impact assessment / Total AI systems",
      "risk_definition": "AI without societal impact assessment may cause widespread harm, disproportionately affect vulnerable populations, and damage organizational reputation.",
      "function_code": "map",
      "category_code": "MAP-3",
      "subcategory_code": "MAP-3.4",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 35,
      "priority_rank": 1,
      "owner_function": "AI Ethics",
      "data_source": "Impact Assessment Records",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MAP-016",
      "name": "AI Risk Criteria Documentation",
      "description": "Percentage of AI systems with documented organizational risk criteria",
      "formula": "AI systems with risk criteria documentation / Total AI systems",
      "risk_definition": "Undefined risk criteria lead to inconsistent risk evaluation, potential acceptance of unacceptable risks, and misaligned risk management decisions.",
      "function_code": "map",
      "category_code": "MAP-3",
      "subcategory_code": "MAP-3.5",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 55,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAP-017",
      "name": "AI Internal Risk Control Documentation",
      "description": "Percentage of AI systems with documented internal risk controls",
      "formula": "AI systems with internal risk controls documented / Total AI systems",
      "risk_definition": "Undocumented risk controls make it difficult to assess AI system security, identify control gaps, and ensure consistent risk management across systems.",
      "function_code": "map",
      "category_code": "MAP-4",
      "subcategory_code": "MAP-4.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 58,
      "priority_rank": 2,
      "owner_function": "AI Security",
      "data_source": "Security Documentation",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MAP-018",
      "name": "AI Stakeholder Engagement Process Maturity",
      "description": "Maturity score of stakeholder engagement practices for AI systems",
      "formula": "Weighted assessment of engagement process maturity criteria",
      "risk_definition": "Immature engagement processes miss critical stakeholder input, fail to identify impacts on affected communities, and reduce trust in AI systems.",
      "function_code": "map",
      "category_code": "MAP-5",
      "subcategory_code": "MAP-5.2",
      "direction": "higher_is_better",
      "target_value": 4,
      "target_units": "level",
      "current_value": 2,
      "priority_rank": 2,
      "owner_function": "Product Management",
      "data_source": "Process Maturity Assessment",
      "collection_frequency": "annually",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MEA-001",
      "name": "AI Model Accuracy",
      "description": "Average accuracy score across production AI models",
      "formula": "Sum of model accuracy scores / Number of production models",
      "risk_definition": "Low model accuracy leads to incorrect predictions and decisions, erodes user trust, causes business losses, and may result in harmful outcomes for affected individuals.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.3",
      "direction": "higher_is_better",
      "target_value": 95,
      "target_units": "percent",
      "current_value": 89,
      "priority_rank": 1,
      "owner_function": "ML Engineering",
      "data_source": "ML Ops Platform",
      "collection_frequency": "weekly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-002",
      "name": "AI Bias Detection Rate",
      "description": "Percentage of AI models tested for bias",
      "formula": "AI models with bias testing / Total production AI models",
      "risk_definition": "Untested models may perpetuate or amplify societal biases, discriminate against protected groups, violate anti-discrimination regulations, and cause significant reputational harm.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.11",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 55,
      "priority_rank": 1,
      "owner_function": "AI Ethics",
      "data_source": "Fairness Testing Platform",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MEA-003",
      "name": "AI Explainability Score",
      "description": "Percentage of AI decisions that can be explained to users",
      "formula": "Explainable AI decisions / Total AI decisions",
      "risk_definition": "Unexplainable AI decisions undermine user trust, prevent meaningful human oversight, complicate dispute resolution, and may violate regulatory requirements for algorithmic transparency.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.9",
      "direction": "higher_is_better",
      "target_value": 90,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 2,
      "owner_function": "ML Engineering",
      "data_source": "Explainability Tools",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "explainable_interpretable"
    },
    {
      "metric_number": "AI-MEA-004",
      "name": "AI Security Testing Coverage",
      "description": "Percentage of AI models with adversarial testing completed",
      "formula": "AI models with adversarial testing / Total production AI models",
      "risk_definition": "AI systems without security testing are vulnerable to adversarial attacks, data poisoning, model extraction, and manipulation that could compromise system integrity and user safety.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.7",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 40,
      "priority_rank": 1,
      "owner_function": "AI Security",
      "data_source": "Security Testing Platform",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MEA-005",
      "name": "AI Model Drift Detection",
      "description": "Percentage of production models with drift monitoring enabled",
      "formula": "Models with drift monitoring / Total production models",
      "risk_definition": "Undetected model drift causes degraded performance over time, leads to increasingly inaccurate predictions, and may result in AI systems operating outside their validated parameters.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.4",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 60,
      "priority_rank": 1,
      "owner_function": "ML Ops",
      "data_source": "ML Ops Platform",
      "collection_frequency": "weekly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-006",
      "name": "AI Privacy Compliance Rate",
      "description": "Percentage of AI systems compliant with privacy requirements",
      "formula": "Privacy-compliant AI systems / Total AI systems processing personal data",
      "risk_definition": "Non-compliant AI systems risk privacy violations, regulatory fines under GDPR/CCPA, erosion of customer trust, and potential misuse of sensitive personal information.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.10",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 78,
      "priority_rank": 1,
      "owner_function": "Privacy/Legal",
      "data_source": "Compliance System",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "privacy_enhanced"
    },
    {
      "metric_number": "AI-MEA-007",
      "name": "AI Risk Metric Coverage",
      "description": "Percentage of identified AI risks with associated measurement metrics",
      "formula": "AI risks with metrics / Total identified AI risks",
      "risk_definition": "Risks without metrics cannot be tracked or measured, preventing data-driven risk management and making it difficult to demonstrate risk reduction progress.",
      "function_code": "measure",
      "category_code": "MEASURE-1",
      "subcategory_code": "MEASURE-1.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 65,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-008",
      "name": "AI Metric Effectiveness Review Rate",
      "description": "Percentage of AI metrics reviewed for effectiveness in the past year",
      "formula": "AI metrics reviewed / Total AI metrics",
      "risk_definition": "Unreviewed metrics may become outdated, measure the wrong things, or fail to capture emerging risks, reducing the effectiveness of AI risk management.",
      "function_code": "measure",
      "category_code": "MEASURE-1",
      "subcategory_code": "MEASURE-1.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 58,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "annually",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-009",
      "name": "AI Independent Assessment Coverage",
      "description": "Percentage of AI systems with independent expert assessment",
      "formula": "AI systems with independent assessment / Total AI systems",
      "risk_definition": "Without independent assessment, development teams may miss issues due to confirmation bias, lack specialized expertise, or overlook risks outside their domain.",
      "function_code": "measure",
      "category_code": "MEASURE-1",
      "subcategory_code": "MEASURE-1.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 35,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Assessment Records",
      "collection_frequency": "annually",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MEA-010",
      "name": "AI Test Documentation Completeness",
      "description": "Percentage of AI systems with complete TEVV documentation",
      "formula": "AI systems with complete test documentation / Total AI systems",
      "risk_definition": "Incomplete test documentation prevents verification of AI quality, complicates troubleshooting, and makes it difficult to demonstrate due diligence in AI development.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "ML Engineering",
      "data_source": "Test Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-011",
      "name": "AI Human Subject Study Compliance",
      "description": "Percentage of AI human subject evaluations meeting ethical requirements",
      "formula": "Compliant human subject studies / Total human subject studies",
      "risk_definition": "Non-compliant human subject research violates ethical principles, may cause harm to participants, and creates legal and reputational risks.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 95,
      "priority_rank": 1,
      "owner_function": "AI Ethics",
      "data_source": "Ethics Review Board",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MEA-012",
      "name": "AI Validation Coverage",
      "description": "Percentage of AI systems validated against documented requirements",
      "formula": "AI systems with validation / Total AI systems",
      "risk_definition": "Unvalidated AI systems may not meet requirements, fail in production, and create risks that proper validation would have identified.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.5",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 1,
      "owner_function": "ML Engineering",
      "data_source": "Test Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-013",
      "name": "AI Purpose Alignment Verification Rate",
      "description": "Percentage of deployed AI systems verified for consistency with intended purpose",
      "formula": "AI systems with purpose verification / Total deployed AI systems",
      "risk_definition": "AI systems operating inconsistently with their intended purpose may cause unexpected harm, fail to deliver benefits, and create liability from misuse.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.6",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 68,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-014",
      "name": "AI Transparency Risk Assessment Rate",
      "description": "Percentage of AI systems assessed for transparency and accountability risks",
      "formula": "AI systems with transparency assessment / Total AI systems",
      "risk_definition": "Unassessed transparency risks may result in AI systems that cannot be audited, explained, or held accountable, undermining trust and regulatory compliance.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.8",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 48,
      "priority_rank": 2,
      "owner_function": "AI Ethics",
      "data_source": "Assessment Records",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MEA-015",
      "name": "AI Environmental Impact Score",
      "description": "Average environmental sustainability score for AI model training and operations",
      "formula": "Weighted average of environmental impact metrics (energy, carbon, resources)",
      "risk_definition": "High environmental impact from AI operations contributes to climate change, may violate sustainability commitments, and creates reputational risks.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.12",
      "direction": "higher_is_better",
      "target_value": 80,
      "target_units": "score",
      "current_value": 55,
      "priority_rank": 3,
      "owner_function": "AI Operations",
      "data_source": "Environmental Monitoring",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-MEA-016",
      "name": "AI TEVV Process Effectiveness Score",
      "description": "Assessment score of TEVV process effectiveness in identifying AI risks",
      "formula": "Weighted evaluation of TEVV process outcomes and improvements",
      "risk_definition": "Ineffective TEVV processes miss critical AI risks, provide false confidence, and fail to prevent deployment of flawed systems.",
      "function_code": "measure",
      "category_code": "MEASURE-2",
      "subcategory_code": "MEASURE-2.13",
      "direction": "higher_is_better",
      "target_value": 85,
      "target_units": "score",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Process Assessment",
      "collection_frequency": "annually",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MEA-017",
      "name": "Third-Party AI Risk Monitoring Rate",
      "description": "Percentage of third-party AI components with active risk monitoring",
      "formula": "Third-party AI with monitoring / Total third-party AI components",
      "risk_definition": "Unmonitored third-party AI creates supply chain blind spots, may introduce unknown risks, and prevents timely response to vendor issues.",
      "function_code": "measure",
      "category_code": "MEASURE-3",
      "subcategory_code": "MEASURE-3.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 52,
      "priority_rank": 1,
      "owner_function": "Vendor Management",
      "data_source": "Vendor Risk Platform",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MEA-018",
      "name": "AI Emerging Risk Tracking Coverage",
      "description": "Percentage of AI systems monitored for emerging and difficult-to-assess risks",
      "formula": "AI systems with emerging risk tracking / Total AI systems",
      "risk_definition": "Failure to track emerging risks allows novel threats to materialize without warning, reduces organizational preparedness, and may result in significant harm before detection.",
      "function_code": "measure",
      "category_code": "MEASURE-3",
      "subcategory_code": "MEASURE-3.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 38,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MEA-019",
      "name": "AI End-User Feedback Response Rate",
      "description": "Percentage of end-user AI feedback items responded to within SLA",
      "formula": "Feedback items responded to in SLA / Total feedback items",
      "risk_definition": "Unresponsive feedback processes frustrate users, miss early warning signals of AI issues, and prevent timely correction of problems.",
      "function_code": "measure",
      "category_code": "MEASURE-3",
      "subcategory_code": "MEASURE-3.3",
      "direction": "higher_is_better",
      "target_value": 95,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 2,
      "owner_function": "Product Support",
      "data_source": "Feedback System",
      "collection_frequency": "weekly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MEA-020",
      "name": "AI Risk Documentation Completeness",
      "description": "Percentage of AI risk measurement approaches with complete documentation",
      "formula": "Fully documented measurement approaches / Total measurement approaches",
      "risk_definition": "Incomplete documentation prevents verification of risk measurement validity, complicates audits, and makes it difficult to improve measurement approaches.",
      "function_code": "measure",
      "category_code": "MEASURE-4",
      "subcategory_code": "MEASURE-4.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Documentation System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MEA-021",
      "name": "AI Trustworthiness Measurement Documentation",
      "description": "Percentage of AI trustworthiness measurements with documented results",
      "formula": "Documented trustworthiness measurements / Total trustworthiness measurements",
      "risk_definition": "Undocumented trustworthiness measurements cannot be verified, tracked over time, or used to demonstrate AI system quality and safety.",
      "function_code": "measure",
      "category_code": "MEASURE-4",
      "subcategory_code": "MEASURE-4.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 55,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Documentation System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MEA-022",
      "name": "AI Performance Reassessment Frequency",
      "description": "Number of periodic AI performance reassessments conducted per year",
      "formula": "Count of AI performance reassessments in period",
      "risk_definition": "Infrequent reassessment allows performance degradation to go undetected, risks operating with outdated understanding of AI capabilities, and may miss emerging issues.",
      "function_code": "measure",
      "category_code": "MEASURE-4",
      "subcategory_code": "MEASURE-4.3",
      "direction": "higher_is_better",
      "target_value": 4,
      "target_units": "per year",
      "current_value": 2,
      "priority_rank": 2,
      "owner_function": "ML Ops",
      "data_source": "Assessment Schedule",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MAN-001",
      "name": "AI Incident Response Time",
      "description": "Average time to respond to AI-related incidents in hours",
      "formula": "Sum of incident response times / Number of AI incidents",
      "risk_definition": "Slow incident response allows AI failures to persist longer, increasing harm to affected users, extending service disruptions, and potentially escalating regulatory scrutiny.",
      "function_code": "manage",
      "category_code": "MANAGE-4",
      "subcategory_code": "MANAGE-4.1",
      "direction": "lower_is_better",
      "target_value": 2,
      "target_units": "hours",
      "current_value": 6.5,
      "priority_rank": 1,
      "owner_function": "AI Operations",
      "data_source": "Incident Management System",
      "collection_frequency": "weekly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-002",
      "name": "AI Model Decommission Compliance",
      "description": "Percentage of retired AI models properly decommissioned",
      "formula": "Properly decommissioned models / Total retired models",
      "risk_definition": "Improperly decommissioned AI models may continue operating without oversight, retain sensitive data inappropriately, or be reactivated without proper validation.",
      "function_code": "manage",
      "category_code": "MANAGE-2",
      "subcategory_code": "MANAGE-2.4",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 85,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-MAN-003",
      "name": "Third-Party AI Risk Monitoring",
      "description": "Percentage of third-party AI components with active monitoring",
      "formula": "Third-party AI components monitored / Total third-party AI components",
      "risk_definition": "Unmonitored third-party AI creates supply chain vulnerabilities, obscures risk exposure, and may introduce security flaws or biases beyond organizational control.",
      "function_code": "manage",
      "category_code": "MANAGE-3",
      "subcategory_code": "MANAGE-3.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 50,
      "priority_rank": 1,
      "owner_function": "Vendor Management",
      "data_source": "Vendor Risk Platform",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MAN-004",
      "name": "AI Stakeholder Feedback Integration",
      "description": "Percentage of stakeholder feedback incorporated into AI improvements",
      "formula": "Feedback items addressed / Total feedback items received",
      "risk_definition": "Ignoring stakeholder feedback leads to AI systems that fail to meet user needs, perpetuate identified issues, and miss opportunities to improve fairness and effectiveness.",
      "function_code": "manage",
      "category_code": "MANAGE-4",
      "subcategory_code": "MANAGE-4.2",
      "direction": "higher_is_better",
      "target_value": 80,
      "target_units": "percent",
      "current_value": 45,
      "priority_rank": 2,
      "owner_function": "AI Product",
      "data_source": "Feedback System",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MAN-005",
      "name": "AI Development Go/No-Go Decision Coverage",
      "description": "Percentage of AI projects with formal go/no-go decision checkpoints",
      "formula": "AI projects with go/no-go gates / Total AI projects",
      "risk_definition": "AI projects without formal checkpoints may proceed despite significant risks, waste resources on flawed approaches, and deploy systems that should have been stopped.",
      "function_code": "manage",
      "category_code": "MANAGE-1",
      "subcategory_code": "MANAGE-1.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 1,
      "owner_function": "AI Governance",
      "data_source": "Project Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-006",
      "name": "AI Risk Treatment Prioritization Rate",
      "description": "Percentage of identified AI risks with prioritized treatment plans",
      "formula": "AI risks with treatment plans / Total identified AI risks",
      "risk_definition": "Unprioritized risk treatment leads to inefficient resource allocation, may address lower risks while critical risks remain unmitigated, and fails to optimize risk reduction.",
      "function_code": "manage",
      "category_code": "MANAGE-1",
      "subcategory_code": "MANAGE-1.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 62,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-007",
      "name": "AI Risk Response Plan Coverage",
      "description": "Percentage of identified AI risks with documented response plans",
      "formula": "AI risks with response plans / Total identified AI risks",
      "risk_definition": "AI risks without response plans leave the organization unprepared when risks materialize, resulting in delayed, ad-hoc responses that may be ineffective.",
      "function_code": "manage",
      "category_code": "MANAGE-1",
      "subcategory_code": "MANAGE-1.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 55,
      "priority_rank": 2,
      "owner_function": "AI Risk Management",
      "data_source": "Risk Management System",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-008",
      "name": "AI Risk Decision Documentation Rate",
      "description": "Percentage of negative AI risk decisions with documented justifications",
      "formula": "Documented risk decisions / Total negative risk decisions",
      "risk_definition": "Undocumented risk decisions prevent accountability, make it difficult to learn from past decisions, and may expose the organization to liability without defense.",
      "function_code": "manage",
      "category_code": "MANAGE-1",
      "subcategory_code": "MANAGE-1.4",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 78,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Decision Log",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-009",
      "name": "AI Risk Management Resource Adequacy",
      "description": "Assessment score of resource adequacy for AI risk management activities",
      "formula": "Weighted evaluation of resource availability vs. requirements",
      "risk_definition": "Inadequate resources prevent effective AI risk management, force prioritization that may leave critical risks unaddressed, and undermine overall AI governance.",
      "function_code": "manage",
      "category_code": "MANAGE-2",
      "subcategory_code": "MANAGE-2.1",
      "direction": "higher_is_better",
      "target_value": 80,
      "target_units": "score",
      "current_value": 58,
      "priority_rank": 2,
      "owner_function": "AI Governance",
      "data_source": "Resource Assessment",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-010",
      "name": "AI System Value Maintenance Rate",
      "description": "Percentage of deployed AI systems maintaining expected value delivery",
      "formula": "AI systems meeting value targets / Total deployed AI systems",
      "risk_definition": "AI systems that fail to maintain value become costly without benefit, may continue consuming resources unnecessarily, and signal potential underlying quality issues.",
      "function_code": "manage",
      "category_code": "MANAGE-2",
      "subcategory_code": "MANAGE-2.2",
      "direction": "higher_is_better",
      "target_value": 90,
      "target_units": "percent",
      "current_value": 75,
      "priority_rank": 2,
      "owner_function": "AI Operations",
      "data_source": "AI Registry",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MAN-011",
      "name": "AI Unknown Risk Response Time",
      "description": "Average time to respond to previously unknown AI risks in hours",
      "formula": "Sum of response times for novel risks / Number of novel risk events",
      "risk_definition": "Slow response to novel risks allows new threats to cause harm before mitigation, demonstrates lack of preparedness, and may result in significant damage.",
      "function_code": "manage",
      "category_code": "MANAGE-2",
      "subcategory_code": "MANAGE-2.3",
      "direction": "lower_is_better",
      "target_value": 4,
      "target_units": "hours",
      "current_value": 12,
      "priority_rank": 1,
      "owner_function": "AI Operations",
      "data_source": "Incident Management System",
      "collection_frequency": "weekly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MAN-012",
      "name": "AI Emergency Deactivation Readiness",
      "description": "Percentage of production AI systems with tested emergency deactivation procedures",
      "formula": "AI systems with tested deactivation / Total production AI systems",
      "risk_definition": "AI systems without deactivation readiness cannot be quickly stopped when critical issues arise, potentially allowing significant harm to continue unchecked.",
      "function_code": "manage",
      "category_code": "MANAGE-2",
      "subcategory_code": "MANAGE-2.4",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 62,
      "priority_rank": 1,
      "owner_function": "AI Operations",
      "data_source": "Runbook Documentation",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "safe"
    },
    {
      "metric_number": "AI-MAN-013",
      "name": "AI Vendor SLA Compliance",
      "description": "Percentage of third-party AI vendors meeting their SLA commitments",
      "formula": "Vendors meeting SLAs / Total AI vendors with SLAs",
      "risk_definition": "Vendors failing SLAs may deliver degraded AI services, create operational risks, and indicate underlying quality or reliability issues.",
      "function_code": "manage",
      "category_code": "MANAGE-3",
      "subcategory_code": "MANAGE-3.1",
      "direction": "higher_is_better",
      "target_value": 95,
      "target_units": "percent",
      "current_value": 82,
      "priority_rank": 2,
      "owner_function": "Vendor Management",
      "data_source": "Vendor Management System",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "secure_resilient"
    },
    {
      "metric_number": "AI-MAN-014",
      "name": "Pre-Trained Model Monitoring Coverage",
      "description": "Percentage of pre-trained models with active monitoring in production",
      "formula": "Monitored pre-trained models / Total pre-trained models in use",
      "risk_definition": "Unmonitored pre-trained models may degrade without detection, introduce unexpected behaviors, and create risks from upstream model changes.",
      "function_code": "manage",
      "category_code": "MANAGE-3",
      "subcategory_code": "MANAGE-3.2",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 48,
      "priority_rank": 1,
      "owner_function": "ML Ops",
      "data_source": "ML Ops Platform",
      "collection_frequency": "weekly",
      "trustworthiness_characteristic": "valid_reliable"
    },
    {
      "metric_number": "AI-MAN-015",
      "name": "AI User Feedback Capture Rate",
      "description": "Percentage of AI system users with accessible feedback mechanisms",
      "formula": "Users with feedback access / Total AI system users",
      "risk_definition": "Users without feedback mechanisms cannot report issues, leading to undetected problems, user frustration, and missed opportunities for improvement.",
      "function_code": "manage",
      "category_code": "MANAGE-4",
      "subcategory_code": "MANAGE-4.1",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 72,
      "priority_rank": 2,
      "owner_function": "Product Management",
      "data_source": "Product Systems",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-016",
      "name": "AI Community Engagement Score",
      "description": "Score measuring quality of engagement with affected communities",
      "formula": "Weighted assessment of community engagement activities and outcomes",
      "risk_definition": "Poor community engagement leads to AI systems that don't serve community needs, miss important impact signals, and damage trust with affected populations.",
      "function_code": "manage",
      "category_code": "MANAGE-4",
      "subcategory_code": "MANAGE-4.2",
      "direction": "higher_is_better",
      "target_value": 80,
      "target_units": "score",
      "current_value": 52,
      "priority_rank": 2,
      "owner_function": "Community Relations",
      "data_source": "Engagement Assessment",
      "collection_frequency": "quarterly",
      "trustworthiness_characteristic": "fair"
    },
    {
      "metric_number": "AI-MAN-017",
      "name": "AI Incident Communication Timeliness",
      "description": "Percentage of AI incidents communicated to stakeholders within required timeframe",
      "formula": "Timely incident communications / Total incident communications required",
      "risk_definition": "Delayed incident communication leaves stakeholders unaware of AI issues, prevents them from taking protective action, and damages trust.",
      "function_code": "manage",
      "category_code": "MANAGE-4",
      "subcategory_code": "MANAGE-4.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 78,
      "priority_rank": 1,
      "owner_function": "Communications",
      "data_source": "Incident Management System",
      "collection_frequency": "weekly",
      "trustworthiness_characteristic": "accountable_transparent"
    },
    {
      "metric_number": "AI-MAN-018",
      "name": "AI Error Disclosure Rate",
      "description": "Percentage of significant AI errors disclosed to affected parties",
      "formula": "Disclosed AI errors / Total significant AI errors",
      "risk_definition": "Undisclosed AI errors prevent affected parties from understanding impacts on them, erode trust when later discovered, and may violate transparency requirements.",
      "function_code": "manage",
      "category_code": "MANAGE-4",
      "subcategory_code": "MANAGE-4.3",
      "direction": "higher_is_better",
      "target_value": 100,
      "target_units": "percent",
      "current_value": 68,
      "priority_rank": 1,
      "owner_function": "AI Governance",
      "data_source": "Incident Management System",
      "collection_frequency": "monthly",
      "trustworthiness_characteristic": "accountable_transparent"
    }
  ]
}
